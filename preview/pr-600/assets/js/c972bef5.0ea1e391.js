"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[87368],{55107:e=>{e.exports=JSON.parse('{"tag":{"label":"concepts","permalink":"/prophecy-docs-staging/preview/pr-600/tags/concepts","allTagsPath":"/prophecy-docs-staging/preview/pr-600/tags","count":13,"items":[{"id":"copilot/copilot","title":"Data Copilot","description":"The AI assistant for data pipelines and models","permalink":"/prophecy-docs-staging/preview/pr-600/data-copilot"},{"id":"copilot/copilot-ai-capabilities","title":"Data Copilot AI capabilities","description":"The AI assistant capabilities for data pipelines and models","permalink":"/prophecy-docs-staging/preview/pr-600/data-copilot-ai-capabilities"},{"id":"copilot/copilot-data-privacy","title":"Data privacy with Data Copilot","description":"The AI assistant data privacy for data pipelines and models","permalink":"/prophecy-docs-staging/preview/pr-600/data-copilot-data-privacy"},{"id":"administration/fabrics/Spark-fabrics/databricks/databricks","title":"Databricks","description":"Configuring Databricks Fabric","permalink":"/prophecy-docs-staging/preview/pr-600/administration/fabrics/Spark-fabrics/databricks/"},{"id":"Spark/dataset","title":"Datasets","description":"Use datasets in your Spark project","permalink":"/prophecy-docs-staging/preview/pr-600/engineers/dataset"},{"id":"administration/self-hosted/enable-data-copilot","title":"Enable Data Copilot","description":"How to enable Prophecy Data Copilot for private VPC SaaS environments.","permalink":"/prophecy-docs-staging/preview/pr-600/administration/self-hosted/enable-data-copilot"},{"id":"getting-started/concepts/Fabric","title":"Fabrics","description":"Run pipelines in execution environments","permalink":"/prophecy-docs-staging/preview/pr-600/fabrics"},{"id":"getting-started/concepts/gems","title":"Gems","description":"Transform your data with Prophecy gems","permalink":"/prophecy-docs-staging/preview/pr-600/gems"},{"id":"data-modeling/Model","title":"Models","description":"SQL models define a single target table or view","permalink":"/prophecy-docs-staging/preview/pr-600/engineers/models"},{"id":"getting-started/concepts/pipelines","title":"Pipelines","description":"Build pipelines in projects to execute data ingestion, transformation, and egress","permalink":"/prophecy-docs-staging/preview/pr-600/pipelines"},{"id":"Spark/pipelines/pipelines","title":"Pipelines","description":"Flows that represent the data journey","permalink":"/prophecy-docs-staging/preview/pr-600/engineers/pipelines"},{"id":"getting-started/concepts/projects","title":"Projects","description":"Keeping your pipelines, datasets and jobs under (source) control","permalink":"/prophecy-docs-staging/preview/pr-600/projects"},{"id":"administration/teams-users/teams-users","title":"Teams and users","description":"Teams represent a group of users who work together","permalink":"/prophecy-docs-staging/preview/pr-600/administration/teams-users/teams-users"}],"unlisted":false}}')}}]);