"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[46875],{64519:e=>{e.exports=JSON.parse('{"tag":{"label":"gems","permalink":"/prophecy-docs-staging/preview/pr-619/tags/gems","allTagsPath":"/prophecy-docs-staging/preview/pr-619/tags","count":77,"items":[{"id":"analysts/development/gems/transform/aggregate","title":"Aggregate","description":"Group and pivot your data","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/aggregate"},{"id":"Spark/gems/transform/aggregate","title":"Aggregate","description":"Group data and apply aggregation methods or pivot operations","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/aggregate"},{"id":"Spark/gems/source-target/file/avro","title":"Avro","description":"Parameters and properties to read from and write to Avro files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/avro"},{"id":"Spark/gems/source-target/warehouse/bigquery","title":"BigQuery","description":"Parameters and properties to read from and write to the BigQuery warehouse","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/bigquery"},{"id":"analysts/development/gems/prepare/bulk-column-expressions","title":"BulkColumnExpressions","description":"Change the data type of multiple columns at once","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/bulk-column-expressions"},{"id":"Spark/gems/transform/bulk-column-expressions","title":"BulkColumnExpressions","description":"Change the data type of multiple columns at once","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/bulk-column-expressions"},{"id":"analysts/development/gems/prepare/bulk-column-rename","title":"BulkColumnRename","description":"Rename multiple columns in your dataset in a systematic way","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/bulk-column-rename"},{"id":"Spark/gems/transform/bulk-column-rename","title":"BulkColumnRename","description":"Rename multiple columns in your dataset in a systematic way","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/bulk-column-rename"},{"id":"Spark/gems/transform/column-parser","title":"ColumnParser","description":"Parse XML or JSON inside a table","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/column-parser"},{"id":"Spark/gems/join-split/compare-columns","title":"CompareColumns","description":"Compare columns between two dataframes","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/compare-columns"},{"id":"Spark/gems/source-target/warehouse/cosmos","title":"CosmosDB","description":"Parameters and properties to read from and write to the CosmosDB warehouse","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/cosmosdb"},{"id":"Spark/gems/source-target/file/csv","title":"CSV","description":"Parameters and properties to read from and write to CSV files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/csv"},{"id":"analysts/development/gems/prepare/data-cleansing","title":"DataCleansing","description":"Standardize data formats","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/data-cleansing"},{"id":"Spark/gems/transform/data-cleansing","title":"DataCleansing","description":"Standardize data formats and address missing or null values in the data","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/data-cleansing"},{"id":"Spark/gems/transform/data-quality-check","title":"DataQualityCheck","description":"Ensure your data adhere to predefined constraints","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/data-quality-check"},{"id":"Spark/gems/source-target/warehouse/db2","title":"DB2","description":"DB2","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/db2"},{"id":"analysts/development/gems/prepare/deduplicate","title":"Deduplicate","description":"Remove duplicates from your data","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/deduplicate"},{"id":"Spark/gems/transform/deduplicate","title":"Deduplicate","description":"Remove rows with duplicate values of specified columns","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/deduplicate"},{"id":"Spark/gems/source-target/file/delta","title":"Delta","description":"Parameters and properties to read from and write to Delta files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/delta"},{"id":"Spark/gems/source-target/catalog-table/delta","title":"Delta Table","description":"Read from or write to tables managed by a Delta table metastore","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/delta-table"},{"id":"Spark/gems/custom/directory","title":"Directory","description":"Return a listing of all the files in a specified directory","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/directory"},{"id":"Spark/gems/transform/dynamic-replace","title":"DynamicReplace","description":"Dynamically generate values depending on certain conditions","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/dynamic-replace"},{"id":"analysts/development/gems/prepare/dynamic-select","title":"DynamicSelect","description":"Dynamically filter columns of your dataset based on a set of conditions","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/dynamic-select"},{"id":"Spark/gems/transform/dynamic-select","title":"DynamicSelect","description":"Dynamically filter columns of your dataset based on a set of conditions","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/dynamic-select"},{"id":"analysts/development/gems/prepare/filter","title":"Filter","description":"Filter the data","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/filter"},{"id":"Spark/gems/transform/filter","title":"Filter","description":"Filter your data based on a custom filter condition","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/filter"},{"id":"Spark/gems/source-target/file/fixed-format","title":"Fixed Format","description":"Parameters and properties to read from and write to Fixed Format files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/fixed-format"},{"id":"analysts/development/gems/prepare/flatten-schema","title":"FlattenSchema","description":"Flatten nested columns","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/flatten-schema"},{"id":"Spark/gems/transform/flatten-schema","title":"FlattenSchema","description":"Flatten nested data","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/flatten-schema"},{"id":"analysts/development/functions/functions","title":"Functions","description":"Build functions with SQL macros to be used in gem expressions","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/functions"},{"id":"Spark/gems/transform/fuzzy-match","title":"FuzzyMatch","description":"Identify non-identical duplicates in your data","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/fuzzy-match"},{"id":"analysts/development/gems/gems","title":"Gems","description":"Power your pipelines with gems","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/gems"},{"id":"getting-started/concepts/gems","title":"Gems","description":"Transform your data with Prophecy gems","permalink":"/prophecy-docs-staging/preview/pr-619/gems"},{"id":"Spark/gems/source-target/catalog-table/hive","title":"Hive Table","description":"Read from or write to tables managed by a Hive metastore","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/hive-table"},{"id":"Spark/gems/source-target/catalog-table/iceberg","title":"Iceberg","description":"Read from or write to tables managed by Iceberg","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/iceberg"},{"id":"Spark/gems/source-target/warehouse/jdbc","title":"JDBC","description":"Parameters and properties to read from and write to the JDBC warehouse","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/jdbc"},{"id":"analysts/development/gems/join-split/join","title":"Join","description":"Join two or more datasets","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/join"},{"id":"Spark/gems/join-split/join","title":"Join","description":"Join one or more DataFrames on conditions","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/join"},{"id":"Spark/gems/source-target/file/json","title":"JSON","description":"Parameters and properties to read from and write to JSON files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/json"},{"id":"Spark/gems/source-target/file/kafka","title":"Kafka","description":"Parameters and properties to read from and write to Kafka files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/kafka"},{"id":"analysts/development/gems/prepare/limit","title":"Limit","description":"Limit the number of columns processed","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/limit"},{"id":"Spark/gems/transform/limit","title":"Limit","description":"Limit the number of rows","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/limit"},{"id":"Spark/gems/source-target/lookup","title":"Lookup","description":"Lookup","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/lookup"},{"id":"analysts/development/gems/custom/macro","title":"Macro","description":"Use dbt macros in your pipelines","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/macro"},{"id":"Spark/gems/source-target/warehouse/mongodb","title":"MongoDB","description":"Parameters and properties to read from and write to the MongoDB warehouse.","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/mongodb"},{"id":"Spark/gems/source-target/warehouse/oracle","title":"Oracle","description":"Oracle","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/oracle"},{"id":"Spark/gems/source-target/file/orc","title":"ORC","description":"Parameters and properties to read from and write to ORC files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/orc"},{"id":"analysts/development/gems/prepare/order-by","title":"OrderBy","description":"Sort the data","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/order-by"},{"id":"Spark/gems/transform/order-by","title":"OrderBy","description":"Sort your data based on one or more columns","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/order-by"},{"id":"Spark/gems/source-target/file/parquet","title":"Parquet","description":"Parameters and properties to read from and write to Parquet files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/parquet"},{"id":"Spark/gems/source-target/warehouse/redshift","title":"Redshift","description":"Parameters and properties to read from and write to the Redshift warehouse.","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/redshift"},{"id":"analysts/development/gems/prepare/reformat","title":"Reformat","description":"Use expressions to reformat column names and values","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/reformat"},{"id":"Spark/gems/transform/reformat","title":"Reformat","description":"Select one or more columns or values using expressions and functions","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/reformat"},{"id":"Spark/gems/join-split/Repartition","title":"Repartition","description":"Repartition or coalesce a DataFrame","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/repartition"},{"id":"analysts/development/gems/custom/rest-api","title":"RestAPI","description":"Call APIs from your pipeline.","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/rest-api"},{"id":"Spark/gems/custom/rest-api-enrich","title":"RestAPIEnrich","description":"Enrich DataFrame with content from rest API response based on configuration","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/rest-api-enrich"},{"id":"Spark/gems/join-split/row-distributor","title":"RowDistributor","description":"Create multiple DataFrames based on filter conditions","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/row-distributor"},{"id":"Spark/gems/source-target/warehouse/salesforce","title":"Salesforce","description":"Salesforce","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/salesforce"},{"id":"Spark/gems/transform/sample-rows","title":"SampleRows","description":"Sample records by choosing a specific number or percentage of records","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/sample-rows"},{"id":"Spark/gems/transform/schema-transform","title":"SchemaTransform","description":"Add, Edit, Rename or Drop Columns","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/schema-transform"},{"id":"Spark/gems/source-target/file/seed","title":"Seed","description":"Parameters and properties to read from Seed files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/seed"},{"id":"Spark/gems/transform/set-operation","title":"SetOperation","description":"Union, Intersect and Difference","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/set-operation"},{"id":"Spark/gems/source-target/warehouse/snowflake","title":"Snowflake","description":"Parameters and properties to read from and write to the Snowflake warehouse.","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/snowflake"},{"id":"Spark/gems/source-target/source-target","title":"Source And Target","description":"Set of gems related to reading and writing data","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/source-target"},{"id":"Spark/spark-streaming/streaming","title":"Spark Structured Streaming","description":"Prophecy Streaming Gems","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/spark-streaming"},{"id":"data-modeling/gems/sql-gems","title":"SQL Gems","description":"Gems are data seeds, sources, transformations, and targets","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/data-modeling-gems"},{"id":"analysts/development/gems/custom/sql-statement","title":"SQL statement","description":"Use a custom SQL statement","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/sql-statement"},{"id":"Spark/gems/custom/sql-statement","title":"SQLStatement","description":"Create DataFrames based on custom SQL queries","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/sql-statement"},{"id":"Spark/gems/source-target/warehouse/teradata","title":"Teradata","description":"Teradata","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/teradata"},{"id":"Spark/gems/source-target/file/text","title":"Text","description":"Parameters and properties to read from and write to Text file","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/text"},{"id":"Spark/gems/transform/unpivot","title":"Unpivot","description":"Use the Unpivot gem to transform your data from a wide format to a long format","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/unpivot"},{"id":"Spark/gems/source-target/file/upload-file","title":"Upload files","description":"Learn how to upload files to your Spark pipeline","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/upload-file"},{"id":"Spark/gems/subgraph/while-iterator","title":"WhileIterator","description":"Recursively processes rows","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/while-iterator"},{"id":"analysts/development/gems/transform/window","title":"Window","description":"Create moving aggregations and transformation","permalink":"/prophecy-docs-staging/preview/pr-619/analysts/window"},{"id":"Spark/gems/transform/window-function","title":"WindowFunction","description":"Aggregate and transform Windowed data","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/window-function"},{"id":"Spark/gems/source-target/file/xlsx","title":"XLSX (Excel)","description":"Parameters and properties to read from and write too XLSX (Excel) files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/xlsx"},{"id":"Spark/gems/source-target/file/xml","title":"XML","description":"Parameters and properties to read from and write to XML files","permalink":"/prophecy-docs-staging/preview/pr-619/engineers/xml"}],"unlisted":false}}')}}]);